Our artificial neural network framework was implemented in Python.
It consists of a single class which takes arguments for {\em (i)} the number of input units {\em (ii)} a list \(H\), where the \(ith\) entry of \(H\) represents the number of units to create at layer \(i\) {\em (iii)} the number of output units {\em (iv)} the learn rate to use during training and {\em (v)} the number of epochs to train the neural network for.
If cross validation is being used the user also has control over the number of folds to create.

A neural network's edge weights from layer \(i\) to layer \(i+1\) are represented by a \(m-by-n\) matrix, where \(m\) is the number of units in layer \(i\) and \(n\) is the number of units in layer \(i+1\).
Additionally, we represent network activations and errors as each layer \(i\) are represented as single row matrices for computational convenience.
As a result, all computations are fast and efficient.
Note, this design choice makes the neural network implementation very comprehensible.

The neural network framework exports an API which allows the developer to {\em (i)} feed a single instance through the network {\em (ii)} run backpropagation {\em (iii)} train on a set of data {\em (iv)} test on a set of data and {\em (v)} print weights, errors, and activations.
The functionality exported by {\em (v)} is for ease of debugging from the command line.

IMPLEMENTATION CHECKLIST:\\
1. Randomized initial values for weights\\
2. Allowing this to be a parameter\\
3. Ensemble implementation (how voting works)\\
4. Sigmoid function (parameterize this as well)
