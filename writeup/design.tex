We implemented our artificial neural network framework in Python.
The framework consists of a single class which takes arguments for {\em (i)} the number of input units {\em (ii)} a list \(H\), where the \(ith\) entry of \(H\) represents the number of units to create at hidden layer \(i\) {\em (iii)} the number of output units {\em (iv)} the learn rate to use during training and {\em (v)} the number of epochs to train the neural network for.
If the user specifies the use of cross validation, the user has control over the number of folds to create from the supplied data set.

When an instance of our neural network class is invoked, all weight matrices are instantiated with random weight values in the range \([-0.1,0.1]\).
Edge weights from layer \(i\) to layer \(i+1\) are represented by a \(m-by-n\) matrix, where \(m\) is the number of units in layer \(i\) and \(n\) is the number of units in layer \(i+1\).
We chose to represent the network activations and errors at each layer \(i\) as single row matrices for computational convenience.
As a result, all computations are fast and efficient.
For the sigmoid function we use \(f(x)=\frac{1}{1+e^{-x}}\).
Note, we plan to extend our framework to include weight initialization and choice of the sigmoid function as initialization parameters.

The framework exports an API which allows the developer to {\em (i)} feed a single instance through the network {\em (ii)} run backpropagation {\em (iii)} train on a set of data {\em (iv)} test on a set of data and {\em (v)} print network weights, errors, and activations.
The functionality exported by {\em (v)} is merely there for comprehensibility and to ease debugging from the command line.

