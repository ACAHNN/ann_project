\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{wolberg1990multisurface}
\citation{mitchell1997artificial}
\citation{markcraven2014}
\citation{Goh1995143}
\citation{alvira2001}
\citation{kim1997nonlinear}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{Introduction\relax }{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Design and Implementation}{2}{section.2}}
\newlabel{sec:design}{{2}{2}{Design and Implementation\relax }{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data Set}{3}{section.3}}
\newlabel{sec:data}{{3}{3}{Data Set\relax }{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{3}{section.4}}
\newlabel{sec:methodology}{{4}{3}{Methodology\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Parameter Space Exploration}{3}{subsection.4.1}}
\newlabel{subsec:parameter}{{4.1}{3}{Parameter Space Exploration\relax }{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Computational Costs}{3}{subsection.4.2}}
\newlabel{subsec:cost}{{4.2}{3}{Computational Costs\relax }{subsection.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{4}{section.5}}
\newlabel{sec:results}{{5}{4}{Results\relax }{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average accuracy on the training and test sets at every epoch from 1 to 400 for a neural network with 14 units at the 1\relax \textsuperscript  {st} hidden layer and 13 units at the 2\relax \textsuperscript  {nd} hidden layer. 10-fold cross validation used during each epoch.\relax }}{4}{figure.caption.3}}
\newlabel{fig:wbcd_iterative}{{2}{4}{Average accuracy on the training and test sets at every epoch from 1 to 400 for a neural network with 14 units at the \nth {1} hidden layer and 13 units at the \nth {2} hidden layer. 10-fold cross validation used during each epoch.\relax \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Accuracy for neural networks with one and two hidden layers. Entry \relax $(i,j)\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.} represents a neural network with \relax $j\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.} units in the 1\relax \textsuperscript  {st} hidden layer and \relax $i\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.} units in the 2\relax \textsuperscript  {nd} hidden layer ({\em  i.e.,} row 0 represents neural networks with only one hidden layer). All combinations were trained for 10 epochs and 10-fold cross validation.\relax }}{5}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:wbcd_table}{{1}{5}{Accuracy for neural networks with one and two hidden layers. Entry \((i,j)\) represents a neural network with \(j\) units in the \nth {1} hidden layer and \(i\) units in the \nth {2} hidden layer ({\em i.e.,} row 0 represents neural networks with only one hidden layer). All combinations were trained for 10 epochs and 10-fold cross validation.\relax \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces True positive rate as a measure of the false positive rate for a neural network with 14 units at the 1\relax \textsuperscript  {st} hidden layer and 13 units at the 2\relax \textsuperscript  {nd} hidden layer. Network trained for 60 epochs using 10-fold cross validation within each epoch.\relax }}{6}{figure.caption.4}}
\newlabel{fig:wbcd_roc}{{3}{6}{True positive rate as a measure of the false positive rate for a neural network with 14 units at the \nth {1} hidden layer and 13 units at the \nth {2} hidden layer. Network trained for 60 epochs using 10-fold cross validation within each epoch.\relax \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Each line represents the predictive accuracy as a function of computational time required to vary the number of perceptrons in the 1\relax \textsuperscript  {st} hidden layer while holding the number of perceptrons in the 2\relax \textsuperscript  {nd} hidden layer constant ({\em  i.e.,} this is equal to generating a row of Figure\nobreakspace  {}\ref  {fig:wbcd_table}\relax }}{6}{figure.caption.5}}
\newlabel{fig:wbcd_timing}{{4}{6}{Each line represents the predictive accuracy as a function of computational time required to vary the number of perceptrons in the \nth {1} hidden layer while holding the number of perceptrons in the \nth {2} hidden layer constant ({\em i.e.,} this is equal to generating a row of Figure~\ref {fig:wbcd_table}\relax \relax }{figure.caption.5}{}}
\bibstyle{plain}
\bibdata{paper}
\bibcite{alvira2001}{1}
\bibcite{markcraven2014}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The predictive accuracy as a function of the computational time required to reach that level of accuracy ({\em  i.e.,} the number of epochs trained). The blue line uses the right hand y-axis and indicates the number of epochs \relax $e\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.} completed at time \relax $t\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.}.\relax }}{7}{figure.caption.6}}
\newlabel{fig:wbcd_iterative_timing}{{5}{7}{The predictive accuracy as a function of the computational time required to reach that level of accuracy ({\em i.e.,} the number of epochs trained). The blue line uses the right hand y-axis and indicates the number of epochs \(e\) completed at time \(t\).\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Summary and Conclusions}{7}{section.6}}
\newlabel{sec:summary}{{6}{7}{Summary and Conclusions\relax }{section.6}{}}
\bibcite{Goh1995143}{3}
\bibcite{kim1997nonlinear}{4}
\bibcite{mitchell1997artificial}{5}
\bibcite{wolberg1990multisurface}{6}
